# Validators/ssd_wrapper.py

import torch
import os
import torchvision
from torchvision.transforms import functional as F
from torchvision.models.detection.anchor_utils import DefaultBoxGenerator
from torchvision.models.detection.ssd import SSDClassificationHead, SSDRegressionHead
from torchvision.ops import Conv2dNormActivation
# ---------------------------------------------------------------
from sahi import AutoDetectionModel
from sahi.predict import get_sliced_prediction

from .model_wrapper import ModelWrapper
from .prediction import Prediction

class SSDWrapper(ModelWrapper):
    """
    Ð£Ð½Ñ–Ð²ÐµÑ€ÑÐ°Ð»ÑŒÐ½Ð° Ð¾Ð±Ð³Ð¾Ñ€Ñ‚ÐºÐ° Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ SSD Ð· Ð¾Ð¿Ñ†Ñ–Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾ÑŽ Ð¿Ñ–Ð´Ñ‚Ñ€Ð¸Ð¼ÐºÐ¾ÑŽ SAHI.
    ÐÐ´Ð°Ð¿Ñ‚Ð¾Ð²Ð°Ð½Ð¾ Ð´Ð»Ñ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹, Ð½Ð°Ð²Ñ‡ÐµÐ½Ð¸Ñ… Ð·Ð° Ð´Ð¾Ð¿Ð¾Ð¼Ð¾Ð³Ð¾ÑŽ SSDTrainer.
    """

    def _select_backbone(self):
        """
        Ð’Ñ–Ð´Ð¾Ð±Ñ€Ð°Ð¶Ð°Ñ” Ð¼ÐµÐ½ÑŽ Ð²Ð¸Ð±Ð¾Ñ€Ñƒ backbone Ñ– Ð¿Ð¾Ð²ÐµÑ€Ñ‚Ð°Ñ” Ð²Ð¸Ð±Ñ–Ñ€ ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ð°.
        """
        print("\nÐ‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð¾Ð±ÐµÑ€Ñ–Ñ‚ÑŒ 'Ñ…Ñ€ÐµÐ±ÐµÑ‚' (backbone) Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»Ñ– SSD, Ñ‰Ð¾ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÑƒÑ”Ñ‚ÑŒÑÑ:")
        print("  1: VGG16 (Ð´Ð»Ñ ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ð¾Ñ— Ð¼Ð¾Ð´ÐµÐ»Ñ– SSD300)")
        print("  2: MobileNetV3-Large (Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»Ñ– SSDLite320)")
        
        while True:
            choice = input("Ð’Ð°Ñˆ Ð²Ð¸Ð±Ñ–Ñ€ (1 Ð°Ð±Ð¾ 2): ").strip()
            if choice == '1':
                print("âœ… ÐžÐ±Ñ€Ð°Ð½Ð¾ Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñƒ Ð½Ð° Ð±Ð°Ð·Ñ– VGG16.")
                return 'vgg16'
            elif choice == '2':
                print("âœ… ÐžÐ±Ñ€Ð°Ð½Ð¾ Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñƒ Ð½Ð° Ð±Ð°Ð·Ñ– MobileNetV3-Large.")
                return 'mobilenet'
            else:
                print("âŒ ÐÐµÐ²Ñ–Ñ€Ð½Ð¸Ð¹ Ð²Ð¸Ð±Ñ–Ñ€. Ð‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð²Ð²ÐµÐ´Ñ–Ñ‚ÑŒ 1 Ð°Ð±Ð¾ 2.")

    def _build_model(self, backbone_type, num_classes):
        """
        Ð¡Ñ‚Ð²Ð¾Ñ€ÑŽÑ” ÐµÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€ Ð¼Ð¾Ð´ÐµÐ»Ñ– Ð· Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð¾ÑŽ Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð¾ÑŽ "Ð³Ð¾Ð»Ð¾Ð²Ð¸",
        Ð°Ð½Ð°Ð»Ð¾Ð³Ñ–Ñ‡Ð½Ð¾ Ð´Ð¾ Ñ‚Ð¾Ð³Ð¾, ÑÐº Ñ†Ðµ Ñ€Ð¾Ð±Ð¸Ñ‚ÑŒÑÑ Ð² SSDTrainer.
        """
        print("ðŸ”§ Ð¡Ñ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð¸ Ð¼Ð¾Ð´ÐµÐ»Ñ– Ð´Ð»Ñ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ð²Ð°Ð³...")
        if backbone_type == 'vgg16':
            model = torchvision.models.detection.ssd300_vgg16(weights=None, num_classes=num_classes)
        else: # mobilenet
            model = torchvision.models.detection.ssdlite320_mobilenet_v3_large(weights=None, num_classes=num_classes)

        # --- Ð’ÐÐ–Ð›Ð˜Ð’Ðž: Ð“ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€ ÑÐºÐ¾Ñ€Ñ–Ð² Ð¼Ð°Ñ” Ð±ÑƒÑ‚Ð¸ Ñ–Ð´ÐµÐ½Ñ‚Ð¸Ñ‡Ð½Ð¸Ð¼ Ñ‚Ð¾Ð¼Ñƒ, Ñ‰Ð¾ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ²Ð°Ð²ÑÑ Ð¿Ñ€Ð¸ Ð½Ð°Ð²Ñ‡Ð°Ð½Ð½Ñ– ---
        model.anchor_generator = DefaultBoxGenerator(
            [
                [0.045, 0.07, 0.1], [0.1, 0.18, 0.25], [0.25, 0.4, 0.5],
                [0.5, 0.6, 0.7], [0.7, 0.8, 0.9], [0.9, 0.93, 0.95] 
            ]
        )
        
        in_channels = []
        for layer in model.head.classification_head.module_list:
            if isinstance(layer, torch.nn.Sequential) and isinstance(layer[0], Conv2dNormActivation):
                in_channels.append(layer[0][0].in_channels)
            else:
                in_channels.append(layer.in_channels)
        
        num_anchors = model.anchor_generator.num_anchors_per_location()
        
        model.head.classification_head = SSDClassificationHead(in_channels, num_anchors, num_classes)
        model.head.regression_head = SSDRegressionHead(in_channels, num_anchors)
        
        return model

    def load(self, model_path, use_sahi=False):
        self.use_sahi = use_sahi
        try:
            backbone_type = self._select_backbone()
            num_classes_for_head = len(self.class_names) + 1
            
            # 1. Ð¡Ñ‚Ð²Ð¾Ñ€ÑŽÑ”Ð¼Ð¾ Ð°Ñ€Ñ…Ñ–Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñƒ Ð¼Ð¾Ð´ÐµÐ»Ñ–
            model_instance = self._build_model(backbone_type, num_classes_for_head)
            
            # 2. Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÑƒÑ”Ð¼Ð¾ Ð²Ð°Ð³Ð¸ Ð· Ñ‡ÐµÐºÐ¿Ð¾Ñ–Ð½Ñ‚Ð°
            state_dict = torch.load(model_path, map_location=self.device).get('model_state_dict', torch.load(model_path, map_location=self.device))
            model_instance.load_state_dict(state_dict)
            model_instance = model_instance.to(self.device).eval()

            if self.use_sahi:
                print("âœ¨ SAHI slicing ENABLED. Ð†Ð½Ñ–Ñ†Ñ–Ð°Ð»Ñ–Ð·Ð°Ñ†Ñ–Ñ AutoDetectionModel Ð· Ð³Ð¾Ñ‚Ð¾Ð²Ð¾ÑŽ Ð¼Ð¾Ð´ÐµÐ»Ð»ÑŽ...")
                self.model = AutoDetectionModel.from_pretrained(
                    model_type='torchvision',  
                    model=model_instance,
                    category_mapping={str(i + 1): name for i, name in enumerate(self.class_names)},
                    device=self.device,
                )
            else:
                print("âœ¨ SAHI slicing DISABLED. Ð’Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑ”Ñ‚ÑŒÑÑ ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ð° Ð¼Ð¾Ð´ÐµÐ»ÑŒ.")
                self.model = model_instance

            print(f"âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ SSD ({backbone_type.upper()}) '{os.path.basename(model_path)}' ÑƒÑÐ¿Ñ–ÑˆÐ½Ð¾ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð°.")
        except Exception as e:
            print(f"âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ° Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÐµÐ½Ð½Ñ Ð¼Ð¾Ð´ÐµÐ»Ñ– SSD: {e}")
            raise

    def predict(self, frame, conf_threshold):
        if hasattr(self, 'use_sahi') and self.use_sahi:
            # Ð›Ð¾Ð³Ñ–ÐºÐ° Ð¿ÐµÑ€ÐµÐ´Ð±Ð°Ñ‡ÐµÐ½Ð½Ñ Ð· Ð½Ð°Ñ€Ñ–Ð·ÐºÐ¾ÑŽ SAHI
            self.model.confidence_threshold = conf_threshold
            
            result = get_sliced_prediction(
                frame,
                detection_model=self.model,
                slice_height=512,
                slice_width=512,
                overlap_height_ratio=0.2,
                overlap_width_ratio=0.2,
            )
            
            predictions = []
            for pred in result.object_prediction_list:
                box = pred.bbox.to_xyxy()
                score = pred.score.value
                class_id = pred.category.id
                class_name = pred.category.name
                
                predictions.append(
                    Prediction(box, score, class_id, class_name, track_id=None)
                )
            return predictions

        else:
            # Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ð° Ð»Ð¾Ð³Ñ–ÐºÐ° Ð¿ÐµÑ€ÐµÐ´Ð±Ð°Ñ‡ÐµÐ½Ð½Ñ Ð±ÐµÐ· Ð½Ð°Ñ€Ñ–Ð·ÐºÐ¸
            predictions = []
            rgb_frame = frame[:, :, ::-1].copy()
            tensor_frame = F.to_tensor(rgb_frame).to(self.device)
            
            with torch.no_grad():
                results = self.model([tensor_frame])[0]

            for box, label, score in zip(results["boxes"], results["labels"], results["scores"]):
                if score.item() >= conf_threshold:
                    class_id = label.item() - 1 
                    if 0 <= class_id < len(self.class_names):
                        class_name = self.class_names[class_id]
                        predictions.append(
                            Prediction(box.cpu().numpy(), score.item(), class_id, class_name, track_id=None)
                        )
            return predictions