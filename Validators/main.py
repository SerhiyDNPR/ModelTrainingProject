# main.py

import cv2
import tkinter as tk
from tkinter import filedialog
import pandas as pd
import os
import torch
import datetime as dt
import json
from Validators.video_processor import VideoProcessor
from Validators.yolo_wrapper import YOLOWrapper
from Validators.yolov9_wrapper import YOLOv9Wrapper
from Validators.detr_wrapper import DETRWrapper
from Validators.deformable_detr_wrapper import DeformableDETRWrapper
from Validators.faster_rcnn_wrapper import FasterRCNNWrapper
from Validators.fcos_wrapper import FCOSWrapper
from Validators.rt_detr_ultralytics_wrapper import RTDETRUltralyticsWrapper
from Validators.mask_rcnn_wrapper import MaskRCNNWrapper
from Validators.retinanet_wrapper import RetinaNetWrapper
from Validators.ssd_wrapper import SSDWrapper
from Validators.efficientdet_wrapper import EfficientDetWrapper
from Validators.cascade_rcnn_wrapper import CascadeRCNNWrapper

# --- –û–°–ù–û–í–ù–Ü –ù–ê–õ–ê–®–¢–£–í–ê–ù–ù–Ø ---
VIDEO_DIR = r"C:\Users\serhi\OneDrive\CD_DSST\Article_syntetic_data\Data_for_tests\Video_interceptors"
FILENAME_FILTER = "–ó–∞–ª–∞"
#CLASS_NAMES = ['Zala', 'SuperCum']
CLASS_NAMES = ['Zala']
CONF_THRESHOLD = 0.5

MODEL_FACTORIES = {
    "YOLOv8": YOLOWrapper,
    "YOLOv9": YOLOv9Wrapper,
    "DETR": DETRWrapper,
    "Deformable DETR": DeformableDETRWrapper,
    "Faster R-CNN (ResNet50/ResNet101/MobileNet/Swin)": FasterRCNNWrapper,
    "Cascade R-CNN (ResNet50/ResNet101)": CascadeRCNNWrapper,
    "FCOS (ResNet50/EfficientNet(?))": FCOSWrapper,
    "RT DETR (Ultralitics)": RTDETRUltralyticsWrapper,
    "Mask R-CNN (ResNet50)": MaskRCNNWrapper,
    "RetinaNet (ResNet50/EfficientNet/Swin)": RetinaNetWrapper,
    "SSD (VGG16/MobileNetV3)": SSDWrapper,
    "EfficientDet": EfficientDetWrapper,
}

sahi_supported_models = ["YOLOv8", "SSD (VGG16/MobileNetV3)"] # <-- –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ, —â–æ –Ω–∞–∑–≤–∞ —Ç—É—Ç —ñ–¥–µ–Ω—Ç–∏—á–Ω–∞

def setup_gui(window_name, processor):
    """–°—Ç–≤–æ—Ä—é—î –≤—ñ–∫–Ω–æ —Ç–∞ —Ç—Ä–µ–∫–±–∞—Ä."""
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    cv2.createTrackbar("Timeline", window_name, 0, 1000, processor.on_trackbar_change)

def load_filters_from_json():
    """–ü—Ä–æ–ø–æ–Ω—É—î –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—É –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Ñ—ñ–ª—å—Ç—Ä–∏ –∑ —Ñ–∞–π–ª—É JSON."""
    root = tk.Tk()
    root.withdraw()
    
    root.attributes('-topmost', True)
    
    filepath = filedialog.askopenfilename(
        title="–û–±–µ—Ä—ñ—Ç—å filters.json –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è (–∞–±–æ —Å–∫–∞—Å—É–π—Ç–µ, —â–æ–± –ø–æ—á–∞—Ç–∏ –∑ –Ω—É–ª—è)",
        filetypes=[("JSON files", "*.json")]
    )
    
    root.attributes('-topmost', False)
    
    if not filepath:
        print("‚ÑπÔ∏è –§–∞–π–ª —Ñ—ñ–ª—å—Ç—Ä—ñ–≤ –Ω–µ –æ–±—Ä–∞–Ω–æ. –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–æ–≤–∏—Ö —Ñ—ñ–ª—å—Ç—Ä—ñ–≤ –∑ –Ω—É–ª—è.")
        return []
        
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            filters_data = json.load(f)
        if isinstance(filters_data, list):
            return filters_data
        else:
            print("‚ö†Ô∏è –§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª—É —Ñ—ñ–ª—å—Ç—Ä—ñ–≤ –Ω–µ–≤—ñ—Ä–Ω–∏–π (–æ—á—ñ–∫—É—î—Ç—å—Å—è —Å–ø–∏—Å–æ–∫). –ü–æ—á–∏–Ω–∞—î–º–æ –∑ –Ω—É–ª—è.")
            return []
    except (json.JSONDecodeError, FileNotFoundError) as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ—ñ–ª—å—Ç—Ä—ñ–≤: {e}. –ü–æ—á–∏–Ω–∞—î–º–æ –∑ –Ω—É–ª—è.")
        return []

def main():
    root = tk.Tk()
    root.withdraw()

    loaded_models = []
    model_choices = list(MODEL_FACTORIES.keys())
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"–û–±—Ä–∞–Ω–æ –ø—Ä–∏—Å—Ç—Ä—ñ–π –¥–ª—è –æ–±—Ä–æ–±–∫–∏: {device.upper()}")

    while True:
        print("\n--- –û–±–µ—Ä—ñ—Ç—å —Ç–∏–ø –º–æ–¥–µ–ª–µ–π –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è ---")
        for j, name in enumerate(model_choices, 1):
            print(f"  {j}: {name}")
        
        try:
            choice_idx = int(input(f"–í–∞—à –≤–∏–±—ñ—Ä —Ç–∏–ø—É –º–æ–¥–µ–ª—ñ: ")) - 1
            if not 0 <= choice_idx < len(model_choices):
                raise ValueError
            model_name = model_choices[choice_idx]
            print(f"‚úÖ –í–∏ –æ–±—Ä–∞–ª–∏ —Ç–∏–ø: {model_name}")
        except (ValueError, IndexError):
            print("‚ùå –ù–µ–≤—ñ—Ä–Ω–∏–π –≤–∏–±—ñ—Ä. –°–ø—Ä–æ–±—É–π—Ç–µ —â–µ —Ä–∞–∑.")
            continue

        root.attributes('-topmost', True)

        model_paths = filedialog.askopenfilenames(
            title=f"–û–±–µ—Ä—ñ—Ç—å –û–î–ò–ù –∞–±–æ –ë–Ü–õ–¨–®–ï —Ñ–∞–π–ª—ñ–≤ –≤–∞–≥ –¥–ª—è '{model_name}' (.pth –∞–±–æ .pt)",
            filetypes=[("Model files", "*.pth *.pt")]
        )
        
        root.attributes('-topmost', False)
        
        if not model_paths:
            print("‚ö†Ô∏è –§–∞–π–ª–∏ –º–æ–¥–µ–ª–µ–π –Ω–µ –æ–±—Ä–∞–Ω–æ. –í–∏–±—ñ—Ä —Ç–∏–ø—É —Å–∫–∞—Å–æ–≤–∞–Ω–æ.")
            add_more = input("\n–ë–∞–∂–∞—î—Ç–µ –¥–æ–¥–∞—Ç–∏ —ñ–Ω—à–∏–π —Ç–∏–ø –º–æ–¥–µ–ª–µ–π? (y/n): ").strip().lower()
            if add_more in ['y', 'Y', '–Ω', '–ù']:
                continue
            else:
                break
                
        
        print(f"üîç –û–±—Ä–∞–Ω–æ {len(model_paths)} —Ñ–∞–π–ª—ñ–≤ –¥–ª—è —Ç–∏–ø—É '{model_name}'. –ù–∞–ª–∞—à—Ç—É–π—Ç–µ –∫–æ–∂–µ–Ω –∑ –Ω–∏—Ö.")

        for model_path in model_paths:
            print(f"\n--- –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –¥–ª—è —Ñ–∞–π–ª—É: {os.path.basename(model_path)} ---")

            use_tracker_for_this_model = False
            use_sahi_for_this_model = False

            if model_name in sahi_supported_models:
                sahi_choice = input(f"–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ SAHI (slicing) –¥–ª—è —Ü—ñ—î—ó –º–æ–¥–µ–ª—ñ? (y/n): ").strip().lower()
                if sahi_choice in ['y', 'Y', '–Ω', '–ù']:
                    use_sahi_for_this_model = True
                    use_tracker_for_this_model = False
                    print("‚úÖ –î–ª—è —Ü—ñ—î—ó –º–æ–¥–µ–ª—ñ –±—É–¥–µ –∑–∞—Å—Ç–æ—Å–æ–≤–∞–Ω–æ SAHI. ByteTrack –≤–∏–º–∫–Ω–µ–Ω–æ, –æ—Å–∫—ñ–ª—å–∫–∏ –≤–æ–Ω–∏ –Ω–µ—Å—É–º—ñ—Å–Ω—ñ.")
            
            if not use_sahi_for_this_model:
                tracker_choice = input(f"–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ ByteTrack –¥–ª—è —Ü—ñ—î—ó –º–æ–¥–µ–ª—ñ? (y/n): ").strip().lower()
                if tracker_choice in ['y', 'Y', '–Ω', '–ù']:
                    use_tracker_for_this_model = True
                    print("‚úÖ –î–ª—è —Ü—ñ—î—ó –º–æ–¥–µ–ª—ñ –±—É–¥–µ –∑–∞—Å—Ç–æ—Å–æ–≤–∞–Ω–æ ByteTrack.")
                else:
                    use_tracker_for_this_model = False
                    print("‚òëÔ∏è –î–ª—è —Ü—ñ—î—ó –º–æ–¥–µ–ª—ñ –±—É–¥–µ –∑–∞—Å—Ç–æ—Å–æ–≤–∞–Ω–æ –∑–≤–∏—á–∞–π–Ω—É –¥–µ—Ç–µ–∫—Ü—ñ—é.")

            try:
                model_wrapper_class = MODEL_FACTORIES[model_name]
                model_wrapper = model_wrapper_class(class_names=CLASS_NAMES, device=device)
                
                if model_name in sahi_supported_models:
                    model_wrapper.load(model_path, use_sahi=use_sahi_for_this_model)
                else:
                    model_wrapper.load(model_path)
                
                filename_no_ext = os.path.splitext(os.path.basename(model_path))[0]
                
                loaded_models.append({
                    'name': model_name,               
                    'filename': filename_no_ext,      
                    'wrapper': model_wrapper,
                    'use_tracker': use_tracker_for_this_model 
                })
                
            except Exception as e:
                print(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å {model_name} –∑ —Ñ–∞–π–ª—É {model_path}. –ü–æ–º–∏–ª–∫–∞: {e}")

        add_more = input("\n–ë–∞–∂–∞—î—Ç–µ –¥–æ–¥–∞—Ç–∏ —ñ–Ω—à–∏–π —Ç–∏–ø –º–æ–¥–µ–ª–µ–π? (y/n): ").strip().lower()
        if add_more not in ['y', 'yes', '—Ç–∞–∫']:
            break

    if not loaded_models:
        print("\n–ù–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –∂–æ–¥–Ω–æ—ó –º–æ–¥–µ–ª—ñ. –í–∏—Ö—ñ–¥.")
        return

    initial_filters = load_filters_from_json()

    timestamp = dt.datetime.now().strftime("%Y-%m-%d_%H%M%S")
    log_filename = f"Comparison_Results_{FILENAME_FILTER}_{timestamp}.csv"
    print(f"\nüìù –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –±—É–¥—É—Ç—å –∑–∞–ø–∏—Å—É–≤–∞—Ç–∏—Å—å —É –Ω–æ–≤–∏–π —Ñ–∞–π–ª: {log_filename}")

    window_name = "Multi-Model Validation"
    
    processor = VideoProcessor(loaded_models, window_name, CONF_THRESHOLD, initial_filters=initial_filters)

    video_files = processor.find_video_files(VIDEO_DIR, FILENAME_FILTER)
    if not video_files: return
    
    setup_gui(window_name, processor)
    
    for video_path in video_files:
        print(f"\n‚ñ∂Ô∏è –û–±—Ä–æ–±–∫–∞ –≤—ñ–¥–µ–æ: {video_path}")
        if processor.run_on_video(video_path):
            print("‚èπÔ∏è –û–±—Ä–æ–±–∫—É –ø–µ—Ä–µ—Ä–≤–∞–Ω–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º.")
            break

    if processor.log_records:
        final_df = pd.DataFrame(processor.log_records)
        final_df.to_csv(log_filename, index=False)
        print(f"\n‚úÖ –û–±—Ä–æ–±–∫—É –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É —Ñ–∞–π–ª—ñ: {log_filename}")
    else:
        print("\n–û–±—Ä–æ–±–∫—É –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è –∑–∞–ø–∏—Å—É.")
    
    cv2.destroyAllWindows()


if __name__ == "__main__":
    main()