import os
import sys
import datetime as dt
import shutil
from glob import glob
import torch
import torch.nn as nn
import torch.optim as optim
import torch.optim.lr_scheduler as lr_scheduler
from torch.utils.data import DataLoader
import torchvision.transforms as T
from tqdm import tqdm

from DataSetUtils.PascalVOCDataset import PascalVOCDataset
from trainers.trainers import BaseTrainer, collate_fn, log_dataset_statistics_to_tensorboard
from torchmetrics.detection import MeanAveragePrecision
from torch.utils.tensorboard import SummaryWriter

# try:
#     from mmengine.config import Config
#     from mmengine.runner import load_checkpoint
#     from mmdet.models import build_detector
#     from mmdet.structures import DetDataSample
#     from mmengine.structures import InstanceData
# except ImportError:
#     print("="*60)
#     print("üî¥ –ü–û–ú–ò–õ–ö–ê: MMDetection –∞–±–æ –π–æ–≥–æ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ!")
#     print("   –ë—É–¥—å –ª–∞—Å–∫–∞, –≤—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å —ó—Ö, –≤–∏–∫–æ–Ω–∞–≤—à–∏ –∫–æ–º–∞–Ω–¥–∏ –∑ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó,")
#     print("   —ñ–Ω–∞–∫—à–µ –Ω–∞–≤—á–∞–Ω–Ω—è Cascade R-CNN –±—É–¥–µ –Ω–µ–º–æ–∂–ª–∏–≤–∏–º.")
#     print("="*60)
#     sys.exit(1)


class MMDetModelWrapper(nn.Module):
    """
    –ö–ª–∞—Å-–æ–±–≥–æ—Ä—Ç–∫–∞ –¥–ª—è –º–æ–¥–µ–ª—ñ –∑ MMDetection, —â–æ –∞–¥–∞–ø—Ç—É—î —ó—ó –¥–ª—è –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è PyTorch/Torchvision.
    """
    def __init__(self, config_path, checkpoint_url, num_classes, backbone_type):
        super().__init__()
        
        # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó
        cfg = Config.fromfile(config_path)
        cfg.model.roi_head.bbox_head[0].num_classes = num_classes - 1
        cfg.model.roi_head.bbox_head[1].num_classes = num_classes - 1
        cfg.model.roi_head.bbox_head[2].num_classes = num_classes - 1
        
        # 2. –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
        self.model = build_detector(cfg.model)

        # 3. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –Ω–∞–≤—á–µ–Ω–∏—Ö –≤–∞–≥
        print(f"üîÑ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤–∞–≥ –¥–ª—è '{backbone_type}' –∑ MMDetection Model Zoo...")
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –≤–∞–≥–∏, —ñ–≥–Ω–æ—Ä—É—é—á–∏ —Ñ—ñ–Ω–∞–ª—å–Ω—ñ —à–∞—Ä–∏ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó, –æ—Å–∫—ñ–ª—å–∫–∏ —ó—Ö —Ä–æ–∑–º—ñ—Ä –∑–º—ñ–Ω–∏–≤—Å—è
        checkpoint = load_checkpoint(self.model, checkpoint_url, map_location='cpu', revise_keys=[(r'^roi_head\.bbox_head\.', '')])
        print("‚úÖ –í–∞–≥–∏ —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ.")

    def forward(self, images, targets=None):
        """
        –£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π forward, —â–æ –ø—Ä–∞—Ü—é—î —ñ –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è, —ñ –¥–ª—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó.
        """
        # MMDetection –æ—á—ñ–∫—É—î –Ω–∞ –≤—Ö—ñ–¥ –±–∞—Ç—á –∑–æ–±—Ä–∞–∂–µ–Ω—å —É –≤–∏–≥–ª—è–¥—ñ –æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞
        if isinstance(images, list):
            # –ü—Ä–æ—Å—Ç–∞ —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—è, —è–∫–∞ –Ω–µ –≤—Ä–∞—Ö–æ–≤—É—î —Ä—ñ–∑–Ω–∏–π —Ä–æ–∑–º—ñ—Ä –∑–æ–±—Ä–∞–∂–µ–Ω—å —É –±–∞—Ç—á—ñ
            # –î–ª—è —Ü—å–æ–≥–æ —Ç—Ä–µ–Ω–µ—Ä–∞ —Ü–µ –û–ö, –æ—Å–∫—ñ–ª—å–∫–∏ —î T.Resize
            images = torch.stack(images, 0)
            
        if self.training and targets is not None:
            # --- –†–ï–ñ–ò–ú –ù–ê–í–ß–ê–ù–ù–Ø ---
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è —Ü—ñ–ª–µ–π –∑ —Ñ–æ—Ä–º–∞—Ç—É torchvision —É —Ñ–æ—Ä–º–∞—Ç MMDetection (DataSample)
            data_samples = []
            for target in targets:
                gt_instances = InstanceData()
                gt_instances.bboxes = target['boxes']
                gt_instances.labels = target['labels']
                
                # –û—Ç—Ä–∏–º—É—î–º–æ —Ä–æ–∑–º—ñ—Ä –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ —Ç–µ–Ω–∑–æ—Ä–∞
                img_meta = {'img_shape': (images.shape[2], images.shape[3])}

                data_sample = DetDataSample(gt_instances=gt_instances, metainfo=img_meta)
                data_samples.append(data_sample)
            
            # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ —Å–ª–æ–≤–Ω–∏–∫ –∑ –≤—Ç—Ä–∞—Ç–∞–º–∏
            losses = self.model.loss(images, data_samples)
            return losses
        else:
            # --- –†–ï–ñ–ò–ú –í–ê–õ–Ü–î–ê–¶–Ü–á ---
            data_samples = [DetDataSample(metainfo={'img_shape': (images.shape[2], images.shape[3])}) for _ in range(images.shape[0])]
            
            # –û—Ç—Ä–∏–º—É—î–º–æ –ø—Ä–æ–≥–Ω–æ–∑–∏
            predictions_list = self.model.predict(images, data_samples)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –∑ —Ñ–æ—Ä–º–∞—Ç—É MMDetection —É torchvision
            results = []
            for pred_sample in predictions_list:
                results.append({
                    'boxes': pred_sample.pred_instances.bboxes,
                    'scores': pred_sample.pred_instances.scores,
                    'labels': pred_sample.pred_instances.labels,
                })
            return results

def get_cascade_rcnn_model_from_mmdet(backbone_type, num_classes):
    """
    –°—Ç–≤–æ—Ä—é—î —Ç–∞ –ø–æ–≤–µ—Ä—Ç–∞—î –º–æ–¥–µ–ª—å Cascade R-CNN –∑ MMDetection.
    """
    if backbone_type == 'resnet50':
        # –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π–Ω–∏–π —Ñ–∞–π–ª –¥–ª—è ResNet-50
        config_path = 'configs/cascade_rcnn/cascade-rcnn_r50_fpn_1x_coco.py'
        # URL –¥–æ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –Ω–∞–≤—á–µ–Ω–æ—ó –º–æ–¥–µ–ª—ñ
        checkpoint_url = 'https://download.openmmlab.com/mmdetection/v2.0/cascade_rcnn/cascade_rcnn_r50_fpn_1x_coco/cascade_rcnn_r50_fpn_1x_coco_20200316-3dc56deb.pth'
    elif backbone_type == 'resnet101':
        # –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π–Ω–∏–π —Ñ–∞–π–ª –¥–ª—è ResNet-101
        config_path = 'configs/cascade_rcnn/cascade-rcnn_r101_fpn_1x_coco.py'
        # URL –¥–æ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –Ω–∞–≤—á–µ–Ω–æ—ó –º–æ–¥–µ–ª—ñ
        checkpoint_url = 'https://download.openmmlab.com/mmdetection/v2.0/cascade_rcnn/cascade_rcnn_r101_fpn_1x_coco/cascade_rcnn_r101_fpn_1x_coco_20200317-0b6a2fbf.pth'
    else:
        raise ValueError(f"–ù–µ–ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏–π backbone '{backbone_type}' –¥–ª—è Cascade R-CNN.")
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ —Ç–∏–º—á–∞—Å–æ–≤—É –ø–∞–ø–∫—É –¥–ª—è –∫–æ–Ω—Ñ—ñ–≥—ñ–≤, —è–∫—â–æ —ó—ó –Ω–µ–º–∞—î
    if not os.path.exists('configs'):
        print("üìÇ –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∏–º—á–∞—Å–æ–≤–æ—ó –ø–∞–ø–∫–∏ 'configs' –¥–ª—è –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤ MMDetection...")
        try:
            # –ö–ª–æ–Ω—É—î–º–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ–π MMDetection, —â–æ–± –æ—Ç—Ä–∏–º–∞—Ç–∏ –∫–æ–Ω—Ñ—ñ–≥–∏
            os.system('git clone https://github.com/open-mmlab/mmdetection.git')
            # –ü–µ—Ä–µ–º—ñ—â—É—î–º–æ –ø–∞–ø–∫—É –∑ –∫–æ–Ω—Ñ—ñ–≥–∞–º–∏
            shutil.move('mmdetection/configs', 'configs')
            # –í–∏–¥–∞–ª—è—î–º–æ —Ä–µ—à—Ç—É —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ—é
            shutil.rmtree('mmdetection')
            print("‚úÖ –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π–Ω—ñ —Ñ–∞–π–ª–∏ —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ.")
        except Exception as e:
            print(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∫–æ–Ω—Ñ—ñ–≥–∏. –ü–æ–º–∏–ª–∫–∞: {e}")
            print("   –ë—É–¥—å –ª–∞—Å–∫–∞, –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —ó—Ö –≤—Ä—É—á–Ω—É –∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ—é MMDetection.")
            sys.exit(1)
            
    return MMDetModelWrapper(config_path, checkpoint_url, num_classes, backbone_type)


class CascadeRCNNTrainer(BaseTrainer):
    """
    –ö–µ—Ä—É—î –ø—Ä–æ—Ü–µ—Å–æ–º –Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ Cascade R-CNN, —ñ–Ω—Ç–µ–≥—Ä–æ–≤–∞–Ω–æ—ó –∑ MMDetection.
    """
    def __init__(self, training_params, dataset_dir):
        super().__init__(training_params, dataset_dir)
        self.backbone_type = None

    def _ask_training_mode(self):
        print("\n   –û–±–µ—Ä—ñ—Ç—å —Ä–µ–∂–∏–º –Ω–∞–≤—á–∞–Ω–Ω—è:")
        print("     1: Fine-tuning (–Ω–∞–≤—á–∞—Ç–∏ —Ç—ñ–ª—å–∫–∏ '–≥–æ–ª–æ–≤–∏' –∫–∞—Å–∫–∞–¥—É, —à–≤–∏–¥—à–µ, —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ)")
        print("     2: Full training (–Ω–∞–≤—á–∞—Ç–∏ –≤—Å—é –º–æ–¥–µ–ª—å, –¥–æ–≤—à–µ)")
        while True:
            sub_choice = input("   –í–∞—à –≤–∏–±—ñ—Ä —Ä–µ–∂–∏–º—É (1 –∞–±–æ 2): ").strip()
            if sub_choice == '1': return '_finetune'
            elif sub_choice == '2': return '_full'
            else: print("   ‚ùå –ù–µ–≤—ñ—Ä–Ω–∏–π –≤–∏–±—ñ—Ä. –ë—É–¥—å –ª–∞—Å–∫–∞, –≤–≤–µ–¥—ñ—Ç—å 1 –∞–±–æ 2.")

    def _select_backbone(self):
        print("\n–ë—É–¥—å –ª–∞—Å–∫–∞, –æ–±–µ—Ä—ñ—Ç—å '—Ö—Ä–µ–±–µ—Ç' (backbone) –¥–ª—è Cascade R-CNN:")
        print("  1: ResNet-50 (–∑–±–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç)")
        print("  2: ResNet-101 (–ø–æ–≤—ñ–ª—å–Ω—ñ—à–∏–π, –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω–æ —Ç–æ—á–Ω—ñ—à–∏–π)")
        while True:
            choice = input("–í–∞—à –≤–∏–±—ñ—Ä (1 –∞–±–æ 2): ").strip()
            backbone_base = None
            if choice == '1':
                print("‚úÖ –í–∏ –æ–±—Ä–∞–ª–∏ ResNet-50."); backbone_base = 'resnet50'
            elif choice == '2':
                print("‚úÖ –í–∏ –æ–±—Ä–∞–ª–∏ ResNet-101."); backbone_base = 'resnet101'
            else:
                print("‚ùå –ù–µ–≤—ñ—Ä–Ω–∏–π –≤–∏–±—ñ—Ä. –ë—É–¥—å –ª–∞—Å–∫–∞, –≤–≤–µ–¥—ñ—Ç—å 1 –∞–±–æ 2."); continue
            training_mode_suffix = self._ask_training_mode()
            return f"{backbone_base}{training_mode_suffix}"

    def _get_model_name(self):
        if self.backbone_type is None: return "Cascade R-CNN (Unknown)"
        parts = self.backbone_type.split('_')
        base_name_map = {'resnet50': 'ResNet50', 'resnet101': 'ResNet101'}
        mode_name_map = {'finetune': 'Fine-tune', 'full': 'Full'}
        base_name = base_name_map.get(parts[0], 'Unknown')
        mode_name = mode_name_map.get(parts[1], 'Training')
        return f"Cascade R-CNN ({base_name} {mode_name})"

    def _get_model(self, num_classes):
        print(f"üîß –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ: {self._get_model_name()}")
        backbone_name = self.backbone_type.split('_')[0]
        
        # –í–∏–∫–ª–∏–∫ –Ω–æ–≤–æ—ó —Ñ—É–Ω–∫—Ü—ñ—ó –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è —Ä–µ–∞–ª—å–Ω–æ—ó –º–æ–¥–µ–ª—ñ
        model_wrapper = get_cascade_rcnn_model_from_mmdet(backbone_name, num_classes)
        
        is_finetune = self.backbone_type.endswith('_finetune')
        if is_finetune:
            print("‚ùÑÔ∏è –ó–∞–º–æ—Ä–æ–∂—É–≤–∞–Ω–Ω—è –≤–∞–≥ backbone. –ù–∞–≤—á–∞–Ω–Ω—è —Ç—ñ–ª—å–∫–∏ '–≥–æ–ª—ñ–≤' (fine-tuning).")
            for param in model_wrapper.model.backbone.parameters():
                param.requires_grad = False
        else:
            print("üî• –£—Å—ñ –≤–∞–≥–∏ –º–æ–¥–µ–ª—ñ —Ä–æ–∑–º–æ—Ä–æ–∂–µ–Ω–æ –¥–ª—è –ø–æ–≤–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è (full training).")
            for param in model_wrapper.model.parameters():
                param.requires_grad = True
        return model_wrapper

    def start_or_resume_training(self, dataset_stats):
        """–ó–∞–ø—É—Å–∫–∞—î –∞–±–æ –≤—ñ–¥–Ω–æ–≤–ª—é—î –Ω–∞–≤—á–∞–Ω–Ω—è."""
        if self.backbone_type is None:
            self.backbone_type = self._select_backbone()

        imgsz = dataset_stats.get('image_size')
        print(f"\n--- –ó–∞–ø—É—Å–∫ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –¥–ª—è {self._get_model_name()} ---")

        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"üîå –û–±—Ä–∞–Ω–æ –ø—Ä–∏—Å—Ç—Ä—ñ–π –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è: {str(device).upper()}")

        project_dir = os.path.join('runs', f'cascade-rcnn-{self.backbone_type}')
        epochs = self.params.get('epochs', 25)
        batch_size = self.params.get('batch', 4)
        learning_rate = self.params.get('lr', 0.0001)
        self.accumulation_steps = self.params.get('accumulation_steps', 1)
        lr_step_size = self.params.get('lr_scheduler_step_size', 8)
        lr_gamma = self.params.get('lr_scheduler_gamma', 0.1)

        train_loader, val_loader, num_classes = self._prepare_dataloaders(batch_size)
        print(f"üìä –ó–Ω–∞–π–¥–µ–Ω–æ {num_classes - 1} –∫–ª–∞—Å—ñ–≤ (+1 —Ñ–æ–Ω). –í—Å—å–æ–≥–æ –∫–ª–∞—Å—ñ–≤ –¥–ª—è –º–æ–¥–µ–ª—ñ: {num_classes}")

        model = self._get_model(num_classes).to(device)
        optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate, weight_decay=1e-4)
        scheduler = lr_scheduler.StepLR(optimizer, step_size=lr_step_size, gamma=lr_gamma)

        run_name, checkpoint_path = self._check_for_resume_rcnn(project_dir)
        start_epoch, best_map = 0, 0.0
        
        run_dir = os.path.join(project_dir, run_name)
        os.makedirs(run_dir, exist_ok=True)
        writer = SummaryWriter(log_dir=os.path.join(run_dir, 'tensorboard_logs'))
        print(f"üìÇ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –±—É–¥—É—Ç—å –∑–±–µ—Ä–µ–∂–µ–Ω—ñ –≤: {run_dir}")

        log_dataset_statistics_to_tensorboard(train_loader.dataset, writer)

        if checkpoint_path:
            model, optimizer, scheduler, start_epoch, best_map = self._load_checkpoint(
                checkpoint_path, model, optimizer, scheduler, device
            )
            print(f"üöÄ –í—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è –Ω–∞–≤—á–∞–Ω–Ω—è –∑ {start_epoch}-—ó –µ–ø–æ—Ö–∏.")

        global_step = 0
        for epoch in range(start_epoch, epochs):
            global_step = self._train_one_epoch(model, optimizer, train_loader, device, epoch, writer, global_step, imgsz)
            val_map = self._validate_one_epoch(model, val_loader, device, imgsz)
            scheduler.step()
            print(f"Epoch {epoch + 1}/{epochs} | Validation mAP: {val_map:.4f}")
            writer.add_scalar('Validation/mAP', val_map, epoch)
            writer.add_scalar('LearningRate/Main', optimizer.param_groups[0]['lr'], epoch)
            is_best = val_map > best_map
            if is_best: best_map = val_map
            self._save_checkpoint({
                'epoch': epoch + 1, 'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(), 'scheduler_state_dict': scheduler.state_dict(),
                'best_map': best_map
            }, is_best, run_dir)

        writer.close()
        print("\nüéâ –ù–∞–≤—á–∞–Ω–Ω—è —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        
        best_model_path = os.path.join(run_dir, "best_model.pth")
        final_path = None
        if os.path.exists(best_model_path):
            final_path = f"Final-{self._get_model_name()}-best.pth"
            shutil.copy(best_model_path, final_path)
            print(f"\n‚úÖ –ù–∞–π–∫—Ä–∞—â—É –º–æ–¥–µ–ª—å —Å–∫–æ–ø—ñ–π–æ–≤–∞–Ω–æ —É —Ñ–∞–π–ª: {final_path} (mAP: {best_map:.4f})")
        
        summary = { "model_name": self._get_model_name(), "best_map": f"{best_map:.4f}", "best_model_path": final_path, "hyperparameters": self.params }
        return summary

    def _prepare_dataloaders(self, batch_size):
        label_map_path = os.path.join(self.dataset_dir, 'label_map.txt')
        with open(label_map_path, 'r', encoding='utf-8') as f:
            class_names = [line.strip() for line in f.readlines()]
        label_map = {name: i for i, name in enumerate(class_names)} # MMDetection –æ—á—ñ–∫—É—î –º—ñ—Ç–∫–∏ –∑ 0
        num_classes = len(label_map) + 1 # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–ª–∞—Å—ñ–≤ + 1 –¥–ª—è —Ñ–æ–Ω—É (–¥–ª—è –ª–æ–≥—ñ–∫–∏)

        train_dataset = PascalVOCDataset(os.path.join(self.dataset_dir, 'train'), transforms=None, label_map=label_map)
        val_dataset = PascalVOCDataset(os.path.join(self.dataset_dir, 'val'), transforms=None, label_map=label_map)
        
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers=0, pin_memory=True)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=0, pin_memory=True)

        return train_loader, val_loader, num_classes

    def _train_one_epoch(self, model, optimizer, data_loader, device, epoch, writer, global_step, imgsz):
        model.train()
        progress_bar = tqdm(data_loader, desc=f"Epoch {epoch + 1} [Train]")
        optimizer.zero_grad()
        
        transforms = T.Compose([T.ToTensor()])
        if imgsz: transforms.transforms.insert(0, T.Resize((imgsz[1], imgsz[0])))
        
        for i, (images, targets) in enumerate(progress_bar):
            images = [transforms(img).to(device) for img in images]
            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
            
            loss_dict = model(images, targets)
            # –°—É–º—É—î–º–æ –≤—Å—ñ –≤—Ç—Ä–∞—Ç–∏ –∑ MMDetection
            losses = sum(loss.mean() for loss in loss_dict.values())
            
            if self.accumulation_steps > 1: losses = losses / self.accumulation_steps
            losses.backward()
            
            if (i + 1) % self.accumulation_steps == 0 or (i + 1) == len(data_loader):
                optimizer.step()
                optimizer.zero_grad()
                display_loss = losses.item() * self.accumulation_steps if self.accumulation_steps > 1 else losses.item()
                writer.add_scalar('Train/Loss_step', display_loss, global_step)
                global_step += 1

            progress_bar.set_postfix(loss=losses.item())
        return global_step

    def _validate_one_epoch(self, model, data_loader, device, imgsz):
        model.eval()
        metric = MeanAveragePrecision(box_format='xyxy').to(device)
        
        transforms = T.Compose([T.ToTensor()])
        if imgsz: transforms.transforms.insert(0, T.Resize((imgsz[1], imgsz[0])))

        with torch.no_grad():
            progress_bar = tqdm(data_loader, desc="Validating")
            for images, targets in progress_bar:
                images_t = [transforms(img).to(device) for img in images]
                targets_for_metric = [{k: v.to(device) for k, v in t.items()} for t in targets]

                predictions = model(images_t)
                metric.update(predictions, targets_for_metric)
        
        mAP_dict = metric.compute()
        return mAP_dict['map'].item()

    def _check_for_resume_rcnn(self, project_path):
        train_dirs = sorted(glob(os.path.join(project_path, "train*")))
        if not train_dirs:
            return f'train_{dt.datetime.now().strftime("%Y%m%d_%H%M%S")}', None
        last_train_dir = train_dirs[-1]
        last_model_path = os.path.join(last_train_dir, "last_checkpoint.pth")
        if os.path.exists(last_model_path):
            print(f"\n‚úÖ –í–∏—è–≤–ª–µ–Ω–æ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è: {last_train_dir}")
            answer = input("–ë–∞–∂–∞—î—Ç–µ –ø—Ä–æ–¥–æ–≤–∂–∏—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è? (y/n): ").strip().lower()
            if answer in ['y', 'yes', '—Ç–∞–∫']:
                print(f"üöÄ –ü—Ä–æ–¥–æ–≤–∂–µ–Ω–Ω—è –∑ —Ñ–∞–π–ª—É: {last_model_path}")
                return os.path.basename(last_train_dir), last_model_path
        print("üóëÔ∏è –ü–æ–ø–µ—Ä–µ–¥–Ω—ñ–π –ø—Ä–æ–≥—Ä–µ—Å –±—É–¥–µ –ø—Ä–æ—ñ–≥–Ω–æ—Ä–æ–≤–∞–Ω–æ.")
        return f'train_{dt.datetime.now().strftime("%Y%m%d_%H%M%S")}', None

    def _save_checkpoint(self, state, is_best, run_dir):
        last_path = os.path.join(run_dir, "last_checkpoint.pth")
        torch.save(state, last_path)
        if is_best:
            best_path = os.path.join(run_dir, "best_model.pth")
            shutil.copyfile(last_path, best_path)

    def _load_checkpoint(self, path, model, optimizer, scheduler, device):
        checkpoint = torch.load(path, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        if 'scheduler_state_dict' in checkpoint:
            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        start_epoch = checkpoint['epoch']
        best_map = checkpoint.get('best_map', 0.0)
        return model, optimizer, scheduler, start_epoch, best_map