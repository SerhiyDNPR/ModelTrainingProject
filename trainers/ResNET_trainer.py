import os
import datetime as dt
import shutil 
from glob import glob
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
import torchvision.transforms as T
import torchvision.models as models
from tqdm import tqdm
from trainers.trainers import BaseTrainer

class ResNetTrainer(BaseTrainer):
    """–ö–µ—Ä—É—î –ø—Ä–æ—Ü–µ—Å–æ–º –Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ ResNet –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é PyTorch."""

    def start_or_resume_training(self, dataset_stats):
        imgsz = dataset_stats.get('image_size')
        print("\n--- –ó–∞–ø—É—Å–∫ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –¥–ª—è ResNet ---")
        
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"üîå –û–±—Ä–∞–Ω–æ –ø—Ä–∏—Å—Ç—Ä—ñ–π –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è: {str(device).upper()}")

        if imgsz:
            print(f"üñºÔ∏è –†–æ–∑–º—ñ—Ä –∑–æ–±—Ä–∞–∂–µ–Ω—å –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è –±—É–¥–µ –∑–º—ñ–Ω–µ–Ω–æ –Ω–∞ {imgsz[0]}x{imgsz[1]}.")
        else:
            print("‚ö†Ô∏è –†–æ–∑–º—ñ—Ä –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è (imgsz) –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–æ, –º–æ–∂–ª–∏–≤–∞ –ø–æ–º–∏–ª–∫–∞.")

        project_dir = self.params.get('project', 'runs/resnet')
        epochs = self.params.get('epochs', 25)
        batch_size = self.params.get('batch', 16)
        learning_rate = self.params.get('lr', 0.001)

        train_loader, val_loader, num_classes, class_names = self._prepare_dataloaders(imgsz, batch_size)
        print(f"üìä –ó–Ω–∞–π–¥–µ–Ω–æ {num_classes} –∫–ª–∞—Å—ñ–≤: {class_names}")

        model = self._get_model(num_classes).to(device)
        optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        criterion = nn.CrossEntropyLoss()

        run_name, checkpoint_path = self._check_for_resume_resnet(project_dir)
        start_epoch = 0
        best_accuracy = 0.0
        final_loss = 0.0

        if checkpoint_path:
            model, optimizer, start_epoch, best_accuracy = self._load_checkpoint(
                checkpoint_path, model, optimizer, device
            )
            print(f"üöÄ –í—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è –Ω–∞–≤—á–∞–Ω–Ω—è –∑ {start_epoch}-—ó –µ–ø–æ—Ö–∏.")
        
        run_dir = os.path.join(project_dir, run_name)
        os.makedirs(run_dir, exist_ok=True)
        print(f"üìÇ –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –±—É–¥—É—Ç—å –∑–±–µ—Ä–µ–∂–µ–Ω—ñ –≤: {run_dir}")

        print(f"\nüöÄ –†–æ–∑–ø–æ—á–∏–Ω–∞—î–º–æ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –Ω–∞ {epochs} –µ–ø–æ—Ö...")
        for epoch in range(start_epoch, epochs):
            train_loss, train_acc = self._train_one_epoch(model, train_loader, criterion, optimizer, device, epoch)
            val_loss, val_acc = self._validate_one_epoch(model, val_loader, criterion, device)

            print(f"Epoch {epoch + 1}/{epochs} | "
                  f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | "
                  f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}")

            is_best = val_acc > best_accuracy
            if is_best:
                best_accuracy = val_acc
                final_loss = val_loss

            self._save_checkpoint({
                'epoch': epoch + 1, 'state_dict': model.state_dict(),
                'optimizer': optimizer.state_dict(), 'best_accuracy': best_accuracy
            }, is_best, run_dir)

        print("\nüéâ –ù–∞–≤—á–∞–Ω–Ω—è —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        
        best_model_path = os.path.join(run_dir, "best_model.pth")
        final_path = None
        if os.path.exists(best_model_path):
            final_path = "Final-ResNet-best.pth"
            shutil.copy(best_model_path, final_path)
            print(f"\n‚úÖ –ù–∞–π–∫—Ä–∞—â—É –º–æ–¥–µ–ª—å —Å–∫–æ–ø—ñ–π–æ–≤–∞–Ω–æ —É —Ñ–∞–π–ª: {final_path} (–¢–æ—á–Ω—ñ—Å—Ç—å: {best_accuracy:.4f})")
        
        summary = {
            "model_name": self._get_model_name(),
            "image_count": dataset_stats.get("image_count", "N/A"),
            "negative_count": dataset_stats.get("negative_count", "N/A"),
            "class_count": dataset_stats.get("class_count", num_classes),
            "image_size": dataset_stats.get("image_size", "N/A"),
            "best_map": f"{best_accuracy:.4f} (Accuracy)",
            "final_loss": f"{final_loss:.4f}",
            "best_model_path": final_path,
            "hyperparameters": self.params
        }
        return summary


    def _prepare_dataloaders(self, imgsz, batch_size):
        """–ì–æ—Ç—É—î –∑–∞–≤–∞–Ω—Ç–∞–∂—É–≤–∞—á—ñ –¥–∞–Ω–∏—Ö –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è —Ç–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó."""
        img_height, img_width = (imgsz[1], imgsz[0]) if isinstance(imgsz, tuple) else (imgsz, imgsz)
        train_transforms = T.Compose([
            T.Resize((img_height, img_width)), T.RandomHorizontalFlip(),
            T.RandomRotation(10), T.ToTensor(),
            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        val_transforms = T.Compose([
            T.Resize((img_height, img_width)), T.ToTensor(),
            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        train_dataset = ImageFolder(root=os.path.join(self.dataset_dir, 'train'), transform=train_transforms)
        val_dataset = ImageFolder(root=os.path.join(self.dataset_dir, 'val'), transform=val_transforms)
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)
        return train_loader, val_loader, len(train_dataset.classes), train_dataset.classes

    def _get_model(self, num_classes):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –Ω–∞–≤—á–µ–Ω—É –º–æ–¥–µ–ª—å ResNet50 —ñ –∞–¥–∞–ø—Ç—É—î —ó—ó."""
        model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
        for param in model.parameters():
            param.requires_grad = False
        num_ftrs = model.fc.in_features
        model.fc = nn.Linear(num_ftrs, num_classes)
        return model

    def _check_for_resume_resnet(self, project_path):
        """–ü–µ—Ä–µ–≤—ñ—Ä—è—î –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è –¥–ª—è ResNet."""
        train_dirs = sorted(glob(os.path.join(project_path, "train*")))
        run_name = f'train_{dt.datetime.now().strftime("%Y%m%d_%H%M%S")}'
        if not train_dirs:
            return run_name, None
        last_train_dir = train_dirs[-1]
        last_model_path = os.path.join(last_train_dir, "last_checkpoint.pth")
        if os.path.exists(last_model_path):
            print(f"\n‚úÖ –í–∏—è–≤–ª–µ–Ω–æ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è: {last_train_dir}")
            answer = input("–ë–∞–∂–∞—î—Ç–µ –ø—Ä–æ–¥–æ–≤–∂–∏—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è –∑ –æ—Å—Ç–∞–Ω–Ω—å–æ—ó —Ç–æ—á–∫–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è? (y/n): ").strip().lower()
            if answer in ['y', 'yes', '—Ç–∞–∫']:
                print(f"üöÄ –ù–∞–≤—á–∞–Ω–Ω—è –±—É–¥–µ –ø—Ä–æ–¥–æ–≤–∂–µ–Ω–æ –∑ —Ñ–∞–π–ª—É: {last_model_path}")
                return os.path.basename(last_train_dir), last_model_path
        print("üóëÔ∏è –ü–æ–ø–µ—Ä–µ–¥–Ω—ñ–π –ø—Ä–æ–≥—Ä–µ—Å –±—É–¥–µ –ø—Ä–æ—ñ–≥–Ω–æ—Ä–æ–≤–∞–Ω–æ. –ù–∞–≤—á–∞–Ω–Ω—è —Ä–æ–∑–ø–æ—á–Ω–µ—Ç—å—Å—è –∑ –Ω—É–ª—è.")
        return run_name, None
        
    def _train_one_epoch(self, model, loader, criterion, optimizer, device, epoch_num):
        """–í–∏–∫–æ–Ω—É—î –æ–¥–Ω—É –µ–ø–æ—Ö—É —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è."""
        model.train()
        running_loss = 0.0
        correct_predictions = 0
        total_samples = 0
        progress_bar = tqdm(loader, desc=f"Epoch {epoch_num + 1} [Train]")
        for inputs, labels in progress_bar:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item() * inputs.size(0)
            _, preds = torch.max(outputs, 1)
            correct_predictions += torch.sum(preds == labels.data)
            total_samples += labels.size(0)
            progress_bar.set_postfix(loss=running_loss/total_samples, acc=correct_predictions.double()/total_samples)
        epoch_loss = running_loss / total_samples
        epoch_acc = correct_predictions.double() / total_samples
        return epoch_loss, epoch_acc.item()

    def _validate_one_epoch(self, model, loader, criterion, device):
        """–í–∏–∫–æ–Ω—É—î –æ–¥–Ω—É –µ–ø–æ—Ö—É –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó."""
        model.eval()
        running_loss = 0.0
        correct_predictions = 0
        total_samples = 0
        with torch.no_grad():
            progress_bar = tqdm(loader, desc="Validating")
            for inputs, labels in progress_bar:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                running_loss += loss.item() * inputs.size(0)
                _, preds = torch.max(outputs, 1)
                correct_predictions += torch.sum(preds == labels.data)
                total_samples += labels.size(0)
                progress_bar.set_postfix(loss=running_loss/total_samples, acc=correct_predictions.double()/total_samples)
        epoch_loss = running_loss / total_samples
        epoch_acc = correct_predictions.double() / total_samples
        return epoch_loss, epoch_acc.item()
    
    def _save_checkpoint(self, state, is_best, run_dir):
        """–ó–±–µ—Ä—ñ–≥–∞—î –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É —Ç–æ—á–∫—É –º–æ–¥–µ–ª—ñ."""
        last_path = os.path.join(run_dir, "last_checkpoint.pth")
        torch.save(state, last_path)
        if is_best:
            best_path = os.path.join(run_dir, "best_model.pth")
            shutil.copyfile(last_path, best_path)

    def _load_checkpoint(self, path, model, optimizer, device):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É —Ç–æ—á–∫—É."""
        checkpoint = torch.load(path, map_location=device)
        model.load_state_dict(checkpoint['state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer'])
        start_epoch = checkpoint['epoch']
        best_accuracy = checkpoint.get('best_accuracy', 0.0)
        return model, optimizer, start_epoch, best_accuracy