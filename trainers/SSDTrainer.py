# trainers/SSDTrainer.py

import os
import sys
import datetime as dt
import shutil 
from glob import glob
import torch
import torch.optim as optim
import torch.optim.lr_scheduler as lr_scheduler
from torch.utils.data import DataLoader
import torchvision.transforms as T
import torchvision.models as models
from tqdm import tqdm
from torchvision.ops import Conv2dNormActivation

from DataSetUtils.PascalVOCDataset import PascalVOCDataset
from trainers.trainers import BaseTrainer, collate_fn, log_dataset_statistics_to_tensorboard
from torchmetrics.detection import MeanAveragePrecision
from torch.utils.tensorboard import SummaryWriter
from torchvision.models.detection.anchor_utils import DefaultBoxGenerator

class SSDTrainer(BaseTrainer):
    """
    ÐšÐµÑ€ÑƒÑ” Ð¿Ñ€Ð¾Ñ†ÐµÑÐ¾Ð¼ Ð½Ð°Ð²Ñ‡Ð°Ð½Ð½Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ SSD (SSD300) Ñ‚Ð° SSDLite (SSD320).
    ÐÐ° Ð¿Ð¾Ñ‡Ð°Ñ‚ÐºÑƒ Ð·Ð°Ð¿Ð¸Ñ‚ÑƒÑ” Ñƒ ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ð°, ÑÐºÐ¸Ð¹ backbone Ñ‚Ð° Ñ€ÐµÐ¶Ð¸Ð¼ Ð½Ð°Ð²Ñ‡Ð°Ð½Ð½Ñ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÐ²Ð°Ñ‚Ð¸.
    """

    def __init__(self, training_params, dataset_dir):
        super().__init__(training_params, dataset_dir)
        self.model_config = None

    def _ask_training_mode(self):
        """Ð”Ð¾Ð¿Ð¾Ð¼Ñ–Ð¶Ð½Ð¸Ð¹ Ð¼ÐµÑ‚Ð¾Ð´, Ñ‰Ð¾ Ð·Ð°Ð¿Ð¸Ñ‚ÑƒÑ” Ñ€ÐµÐ¶Ð¸Ð¼ Ð½Ð°Ð²Ñ‡Ð°Ð½Ð½Ñ."""
        print("\n   ÐžÐ±ÐµÑ€Ñ–Ñ‚ÑŒ Ñ€ÐµÐ¶Ð¸Ð¼ Ð½Ð°Ð²Ñ‡Ð°Ð½Ð½Ñ:")
        print("     1: Fine-tuning (Ð½Ð°Ð²Ñ‡Ð°Ñ‚Ð¸ Ñ‚Ñ–Ð»ÑŒÐºÐ¸ 'Ð³Ð¾Ð»Ð¾Ð²Ñƒ', ÑˆÐ²Ð¸Ð´ÑˆÐµ, Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð¾Ð²Ð°Ð½Ð¾)")
        print("     2: Full training (Ð½Ð°Ð²Ñ‡Ð°Ñ‚Ð¸ Ð²ÑÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ, Ð´Ð¾Ð²ÑˆÐµ)")
        while True:
            sub_choice = input("   Ð’Ð°Ñˆ Ð²Ð¸Ð±Ñ–Ñ€ Ñ€ÐµÐ¶Ð¸Ð¼Ñƒ (1 Ð°Ð±Ð¾ 2): ").strip()
            if sub_choice == '1':
                return '_finetune'
            elif sub_choice == '2':
                return '_full'
            else:
                print("   âŒ ÐÐµÐ²Ñ–Ñ€Ð½Ð¸Ð¹ Ð²Ð¸Ð±Ñ–Ñ€. Ð‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð²Ð²ÐµÐ´Ñ–Ñ‚ÑŒ 1 Ð°Ð±Ð¾ 2.")

    def _select_backbone_and_mode(self):
        """Ð’Ñ–Ð´Ð¾Ð±Ñ€Ð°Ð¶Ð°Ñ” Ð¼ÐµÐ½ÑŽ Ð²Ð¸Ð±Ð¾Ñ€Ñƒ backbone Ñ‚Ð° Ñ€ÐµÐ¶Ð¸Ð¼Ñƒ, Ñ– Ð¿Ð¾Ð²ÐµÑ€Ñ‚Ð°Ñ” ÐºÐ¾Ð¼Ð±Ñ–Ð½Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ñ€ÑÐ´Ð¾Ðº."""
        print("\nÐ‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð¾Ð±ÐµÑ€Ñ–Ñ‚ÑŒ 'Ñ…Ñ€ÐµÐ±ÐµÑ‚' (backbone) Ð´Ð»Ñ SSD:")
        print("  1: VGG16 (ÐºÐ»Ð°ÑÐ¸Ñ‡Ð½Ð¸Ð¹, Ñ‚Ð¾Ñ‡Ð½Ð¸Ð¹, Ð°Ð»Ðµ Ð¿Ð¾Ð²Ñ–Ð»ÑŒÐ½Ð¸Ð¹)")
        print("  2: MobileNetV3-Large (ÑÑƒÑ‡Ð°ÑÐ½Ð¸Ð¹, Ð´ÑƒÐ¶Ðµ ÑˆÐ²Ð¸Ð´ÐºÐ¸Ð¹, Ð´Ð»Ñ real-time)")
        
        while True:
            choice = input("Ð’Ð°Ñˆ Ð²Ð¸Ð±Ñ–Ñ€ (1 Ð°Ð±Ð¾ 2): ").strip()
            backbone_base = None
            if choice == '1':
                print("âœ… Ð’Ð¸ Ð¾Ð±Ñ€Ð°Ð»Ð¸ VGG16.")
                backbone_base = 'vgg16'
            elif choice == '2':
                print("âœ… Ð’Ð¸ Ð¾Ð±Ñ€Ð°Ð»Ð¸ MobileNetV3-Large (SSDLite).")
                backbone_base = 'mobilenet'
            else:
                print("âŒ ÐÐµÐ²Ñ–Ñ€Ð½Ð¸Ð¹ Ð²Ð¸Ð±Ñ–Ñ€. Ð‘ÑƒÐ´ÑŒ Ð»Ð°ÑÐºÐ°, Ð²Ð²ÐµÐ´Ñ–Ñ‚ÑŒ 1 Ð°Ð±Ð¾ 2.")
                continue

            training_mode_suffix = self._ask_training_mode()
            self.model_config = f"{backbone_base}{training_mode_suffix}"
            return self.model_config

    def _get_model_name(self):
        """ÐŸÐ¾Ð²ÐµÑ€Ñ‚Ð°Ñ” Ð¿Ð¾Ð²Ð½Ñƒ Ð½Ð°Ð·Ð²Ñƒ Ð¼Ð¾Ð´ÐµÐ»Ñ– Ð´Ð»Ñ Ð»Ð¾Ð³ÑƒÐ²Ð°Ð½Ð½Ñ, Ð±Ð°Ð·ÑƒÑŽÑ‡Ð¸ÑÑŒ Ð½Ð° Ð²Ð¸Ð±Ð¾Ñ€Ñ– ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ð°."""
        if not self.model_config: return "SSD (Unknown)"
        parts = self.model_config.split('_')
        base_name = "SSD (VGG16)" if parts[0] == 'vgg16' else "SSDLite (MobileNetV3)"
        mode_name = "Fine-tune" if parts[1] == 'finetune' else "Full"
        return f"{base_name} {mode_name}"
    
    def _get_model(self, num_classes):
        """Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶ÑƒÑ” Ð¼Ð¾Ð´ÐµÐ»ÑŒ SSD Ð· Ð¾Ð±Ñ€Ð°Ð½Ð¸Ð¼ backbone Ñ‚Ð° Ñ€ÐµÐ¶Ð¸Ð¼Ð¾Ð¼ Ð½Ð°Ð²Ñ‡Ð°Ð½Ð½Ñ."""
        print(f"ðŸ”§ Ð¡Ñ‚Ð²Ð¾Ñ€ÐµÐ½Ð½Ñ Ð¼Ð¾Ð´ÐµÐ»Ñ–: {self._get_model_name()}")
        
        is_finetune = self.model_config.endswith('_finetune')
        
        if self.model_config.startswith('vgg16'):
            model = models.detection.ssd300_vgg16(weights=models.detection.SSD300_VGG16_Weights.DEFAULT)
        elif self.model_config.startswith('mobilenet'):
            model = models.detection.ssdlite320_mobilenet_v3_large(weights=models.detection.SSDLite320_MobileNet_V3_Large_Weights.DEFAULT)
        else:
            sys.exit(f"âŒ ÐŸÐ¾Ð¼Ð¸Ð»ÐºÐ°: Ð½ÐµÐ²Ñ–Ð´Ð¾Ð¼Ð¸Ð¹ Ñ‚Ð¸Ð¿ ÐºÐ¾Ð½Ñ„Ñ–Ð³ÑƒÑ€Ð°Ñ†Ñ–Ñ— '{self.model_config}'.")

        model.anchor_generator = DefaultBoxGenerator(
            [
                # ÐšÐ°Ñ€Ñ‚Ð° Ð¾Ð·Ð½Ð°Ðº 1 (Ð´Ð»Ñ Ð½Ð°Ð¹Ð¼ÐµÐ½ÑˆÐ¸Ñ… Ð¾Ð±'Ñ”ÐºÑ‚Ñ–Ð²)
                # ÐŸÐ¾ÐºÑ€Ð¸Ð²Ð°Ñ” Ñ€Ð¾Ð·Ð¼Ñ–Ñ€Ð¸ ~28-64 Ð¿Ñ–ÐºÑÐµÐ»Ñ–Ð²
                [0.045, 0.07, 0.1],
                
                # ÐšÐ°Ñ€Ñ‚Ð° Ð¾Ð·Ð½Ð°Ðº 2 
                # ÐŸÐ¾ÐºÑ€Ð¸Ð²Ð°Ñ” Ñ€Ð¾Ð·Ð¼Ñ–Ñ€Ð¸ ~64-160 Ð¿Ñ–ÐºÑÐµÐ»Ñ–Ð²
                [0.1, 0.18, 0.25],
                
                # ÐšÐ°Ñ€Ñ‚Ð° Ð¾Ð·Ð½Ð°Ðº 3 (Ð´Ð»Ñ ÑÐµÑ€ÐµÐ´Ð½Ñ–Ñ… Ð¾Ð±'Ñ”ÐºÑ‚Ñ–Ð²)
                # ÐŸÐ¾ÐºÑ€Ð¸Ð²Ð°Ñ” Ñ€Ð¾Ð·Ð¼Ñ–Ñ€Ð¸ ~160-320 Ð¿Ñ–ÐºÑÐµÐ»Ñ–Ð²
                [0.25, 0.4, 0.5],
                
                # ÐšÐ°Ñ€Ñ‚Ð° Ð¾Ð·Ð½Ð°Ðº 4
                # ÐŸÐ¾ÐºÑ€Ð¸Ð²Ð°Ñ” Ñ€Ð¾Ð·Ð¼Ñ–Ñ€Ð¸ ~320-450 Ð¿Ñ–ÐºÑÐµÐ»Ñ–Ð²
                [0.5, 0.6, 0.7],
                
                # ÐšÐ°Ñ€Ñ‚Ð° Ð¾Ð·Ð½Ð°Ðº 5 (Ð´Ð»Ñ Ð²ÐµÐ»Ð¸ÐºÐ¸Ñ… Ð¾Ð±'Ñ”ÐºÑ‚Ñ–Ð²)
                # ÐŸÐ¾ÐºÑ€Ð¸Ð²Ð°Ñ” Ñ€Ð¾Ð·Ð¼Ñ–Ñ€Ð¸ ~450-575 Ð¿Ñ–ÐºÑÐµÐ»Ñ–Ð²
                [0.7, 0.8, 0.9],
                
                # ÐšÐ°Ñ€Ñ‚Ð° Ð¾Ð·Ð½Ð°Ðº 6 (Ð´Ð»Ñ Ð½Ð°Ð¹Ð±Ñ–Ð»ÑŒÑˆÐ¸Ñ… Ð¾Ð±'Ñ”ÐºÑ‚Ñ–Ð²)
                # ÐŸÐ¾ÐºÑ€Ð¸Ð²Ð°Ñ” Ñ€Ð¾Ð·Ð¼Ñ–Ñ€Ð¸ ~575-608 Ð¿Ñ–ÐºÑÐµÐ»Ñ–Ð²
                [0.9, 0.93, 0.95] 
            ]
        )

        in_channels = []
        # Ð¦ÐµÐ¹ Ð±Ð»Ð¾Ðº Ð·Ð°Ð»Ð¸ÑˆÐ°Ñ”Ñ‚ÑŒÑÑ Ð±ÐµÐ· Ð·Ð¼Ñ–Ð½
        for layer in model.head.classification_head.module_list:
            if isinstance(layer, torch.nn.Sequential) and isinstance(layer[0], Conv2dNormActivation):
                in_channels.append(layer[0][0].in_channels)
            else:
                in_channels.append(layer.in_channels)
        
        # ÐžÑ‚Ñ€Ð¸Ð¼ÑƒÑ”Ð¼Ð¾ ÐºÑ–Ð»ÑŒÐºÑ–ÑÑ‚ÑŒ ÑÐºÐ¾Ñ€Ñ–Ð² Ð· Ð²Ð°ÑˆÐ¾Ð³Ð¾ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ð³ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ð°
        num_anchors = model.anchor_generator.num_anchors_per_location()
        
        # ÐžÐ½Ð¾Ð²Ð»ÑŽÑ”Ð¼Ð¾ ÐºÐ»Ð°ÑÐ¸Ñ„Ñ–ÐºÐ°Ñ†Ñ–Ð¹Ð½Ñƒ Ð³Ð¾Ð»Ð¾Ð²Ñƒ (Ñ†Ðµ Ñƒ Ð²Ð°Ñ Ð²Ð¶Ðµ Ð±ÑƒÐ»Ð¾)
        model.head.classification_head = models.detection.ssd.SSDClassificationHead(
            in_channels, num_anchors, num_classes)
            
        # Ð¡Ñ‚Ð²Ð¾Ñ€ÑŽÑ”Ð¼Ð¾ Ð½Ð¾Ð²Ñƒ Ñ€ÐµÐ³Ñ€ÐµÑÑ–Ð¹Ð½Ñƒ Ð³Ð¾Ð»Ð¾Ð²Ñƒ, ÑÐºÐ° Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´Ð°Ñ” Ð½Ð¾Ð²Ñ–Ð¹ ÐºÑ–Ð»ÑŒÐºÐ¾ÑÑ‚Ñ– ÑÐºÐ¾Ñ€Ñ–Ð²
        model.head.regression_head = models.detection.ssd.SSDRegressionHead(
            in_channels, num_anchors)
        # ---------------------------
            
        if is_finetune:
            print("â„ï¸ Ð—Ð°Ð¼Ð¾Ñ€Ð¾Ð¶ÑƒÐ²Ð°Ð½Ð½Ñ Ð²Ð°Ð³ backbone (fine-tuning).")
            for param in model.backbone.parameters():
                param.requires_grad = False
        else:
            print("ðŸ”¥ Ð£ÑÑ– Ð²Ð°Ð³Ð¸ Ð¼Ð¾Ð´ÐµÐ»Ñ– Ñ€Ð¾Ð·Ð¼Ð¾Ñ€Ð¾Ð¶ÐµÐ½Ð¾ Ð´Ð»Ñ Ð¿Ð¾Ð²Ð½Ð¾Ð³Ð¾ Ð½Ð°Ð²Ñ‡Ð°Ð½Ð½Ñ (full training).")

        return model

    def start_or_resume_training(self, dataset_stats):
        if self.model_config is None:
            self._select_backbone_and_mode()

        print(f"\n--- Ð—Ð°Ð¿ÑƒÑÐº Ñ‚Ñ€ÐµÐ½ÑƒÐ²Ð°Ð½Ð½Ñ Ð´Ð»Ñ {self._get_model_name()} ---")
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        imgsz = (640, 640)
        if self.model_config.startswith('vgg16'):
            project_dir = os.path.join('runs', f'ssd-vgg16{self.model_config.split("vgg16")[-1]}')
        else: # mobilenet
            project_dir = os.path.join('runs', f'ssdlite-mobilenet{self.model_config.split("mobilenet")[-1]}')
            
        print(f"ðŸ”Œ ÐžÐ±Ñ€Ð°Ð½Ð¾ Ð¿Ñ€Ð¸ÑÑ‚Ñ€Ñ–Ð¹: {str(device).upper()}. Ð Ð¾Ð·Ð¼Ñ–Ñ€ Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½ÑŒ: {imgsz[0]}x{imgsz[1]}.")

        epochs, batch_size, lr = self.params['epochs'], self.params['batch'], self.params['lr']
        self.accumulation_steps = self.params.get('accumulation_steps', 1)

        train_loader, val_loader, num_classes = self._prepare_dataloaders(batch_size)
        model = self._get_model(num_classes).to(device)

        #optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)
        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)

        lr_step_size = self.params.get('lr_scheduler_step_size', 8)
        lr_gamma = self.params.get('lr_scheduler_gamma', 0.1)
        scheduler = lr_scheduler.StepLR(optimizer, step_size=lr_step_size, gamma=lr_gamma)
        
        run_name, ckpt_path = self._check_for_resume(project_dir)
        start_epoch, best_map, global_step = self._load_checkpoint(ckpt_path, model, optimizer, scheduler, device)
        
        run_dir = os.path.join(project_dir, run_name)
        os.makedirs(run_dir, exist_ok=True)
        writer = SummaryWriter(log_dir=os.path.join(run_dir, 'tensorboard_logs'))
        
        try:
            log_dataset_statistics_to_tensorboard(train_loader.dataset, writer)
            print(f"\nðŸš€ Ð Ð¾Ð·Ð¿Ð¾Ñ‡Ð¸Ð½Ð°Ñ”Ð¼Ð¾ Ñ‚Ñ€ÐµÐ½ÑƒÐ²Ð°Ð½Ð½Ñ Ð½Ð° {epochs} ÐµÐ¿Ð¾Ñ…...")
            
            for epoch in range(start_epoch, epochs):
                global_step = self._train_one_epoch(model, optimizer, train_loader, device, epoch, writer, global_step, imgsz)
                val_map = self._validate_one_epoch(model, val_loader, device, imgsz)
                scheduler.step()
                
                print(f"Epoch {epoch + 1}/{epochs} | Validation mAP: {val_map:.4f}")
                writer.add_scalar('Validation/mAP', val_map, epoch)
                writer.add_scalar('LearningRate/Main', optimizer.param_groups[0]['lr'], epoch)

                writer.flush()

                is_best = val_map > best_map
                if is_best: best_map = val_map
                self._save_checkpoint(epoch + 1, model, optimizer, scheduler, best_map, global_step, is_best, run_dir)
                epoch_state = {
                    'epoch': epoch + 1,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'scheduler_state_dict': scheduler.state_dict(),
                    'best_map': best_map,
                    'global_step': global_step
                }
                epoch_ckpt_path = os.path.join(run_dir, f"epoch_{epoch + 1:03d}.pth")
                torch.save(epoch_state, epoch_ckpt_path)
                print(f"ðŸ’¾ Ð—Ð±ÐµÑ€ÐµÐ¶ÐµÐ½Ð¾ Ð²Ð°Ð³Ð¸ Ð¿Ð¾Ñ‚Ð¾Ñ‡Ð½Ð¾Ñ— ÐµÐ¿Ð¾Ñ…Ð¸: {epoch_ckpt_path}")
        finally:
            # <-- Ð”ÐžÐ”ÐÐÐž: Ð“Ð°Ñ€Ð°Ð½Ñ‚Ð¾Ð²Ð°Ð½Ðµ Ð·Ð°ÐºÑ€Ð¸Ñ‚Ñ‚Ñ writer, Ð½Ð°Ð²Ñ–Ñ‚ÑŒ Ð¿Ñ€Ð¸ Ð¿ÐµÑ€ÐµÑ€Ð¸Ð²Ð°Ð½Ð½Ñ–
            writer.close()
            print("\nðŸŽ‰ ÐÐ°Ð²Ñ‡Ð°Ð½Ð½Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾ Ð°Ð±Ð¾ Ð¿ÐµÑ€ÐµÑ€Ð²Ð°Ð½Ð¾. Writer Ð·Ð°ÐºÑ€Ð¸Ñ‚Ð¾.")


    def _prepare_dataloaders(self, batch_size):
        label_map_path = os.path.join(self.dataset_dir, 'label_map.txt')
        with open(label_map_path, 'r') as f: class_names = [line.strip() for line in f.readlines()]
        label_map = {name: i+1 for i, name in enumerate(class_names)}
        num_classes = len(class_names) + 1
        train_dataset = PascalVOCDataset(os.path.join(self.dataset_dir, 'train'), transforms=None, label_map=label_map)
        val_dataset = PascalVOCDataset(os.path.join(self.dataset_dir, 'val'), transforms=None, label_map=label_map)
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)
        return train_loader, val_loader, num_classes

    def _train_one_epoch(self, model, optimizer, data_loader, device, epoch, writer, global_step, imgsz):
        model.train()
        progress_bar = tqdm(data_loader, desc=f"Epoch {epoch + 1} [Train]")
        transforms = T.Compose([T.Resize(imgsz), T.ToTensor()])
        optimizer.zero_grad()
        for i, (images, targets) in enumerate(progress_bar):
            images = [transforms(img).to(device) for img in images]
            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
            loss_dict = model(images, targets)
            losses = sum(loss for loss in loss_dict.values())
            losses = losses / self.accumulation_steps
            losses.backward()
            if (i + 1) % self.accumulation_steps == 0 or (i + 1) == len(data_loader):
                optimizer.step()
                optimizer.zero_grad()
                writer.add_scalar('Train/Loss_step', losses.item() * self.accumulation_steps, global_step)
                global_step += 1
            progress_bar.set_postfix(loss=losses.item() * self.accumulation_steps)
        return global_step

    def _validate_one_epoch(self, model, data_loader, device, imgsz):
        model.eval()
        metric = MeanAveragePrecision(box_format='xyxy').to(device)
        transforms = T.Compose([T.Resize(imgsz), T.ToTensor()])
        with torch.no_grad():
            for images, targets in tqdm(data_loader, desc="Validating"):
                images = [transforms(img).to(device) for img in images]
                predictions = model(images)
                metric.update(predictions, [{k: v.to(device) for k, v in t.items()} for t in targets])
        return metric.compute()['map'].item()

    def _check_for_resume(self, project_path):
        train_dirs = sorted(glob(os.path.join(project_path, "train*")))
        if not train_dirs: return f'train_{dt.datetime.now().strftime("%Y%m%d_%H%M%S")}', None
        last_dir = train_dirs[-1]
        last_ckpt = os.path.join(last_dir, "last_checkpoint.pth")
        if os.path.exists(last_ckpt):
            print(f"\nâœ… Ð’Ð¸ÑÐ²Ð»ÐµÐ½Ð¾ Ð½ÐµÐ·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ðµ Ð½Ð°Ð²Ñ‡Ð°Ð½Ð½Ñ: {last_dir}")
            if input("Ð‘Ð°Ð¶Ð°Ñ”Ñ‚Ðµ Ð¿Ñ€Ð¾Ð´Ð¾Ð²Ð¶Ð¸Ñ‚Ð¸? (y/n): ").strip().lower() in ['y', 'yes', 'Ñ‚Ð°Ðº', 'Ð½']:
                return os.path.basename(last_dir), last_ckpt
        return f'train_{dt.datetime.now().strftime("%Y%m%d_%H%M%S")}', None
    
    def _load_checkpoint(self, path, model, optimizer, scheduler, device):
        if not path: return 0, 0.0, 0
        try:
            ckpt = torch.load(path, map_location=device)
            model.load_state_dict(ckpt['model_state_dict'])
            optimizer.load_state_dict(ckpt['optimizer_state_dict'])
            scheduler.load_state_dict(ckpt['scheduler_state_dict'])
            print(f"ðŸš€ Ð’Ñ–Ð´Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ Ð½Ð°Ð²Ñ‡Ð°Ð½Ð½Ñ Ð· {ckpt['epoch']}-Ñ— ÐµÐ¿Ð¾Ñ…Ð¸.")
            return ckpt['epoch'], ckpt.get('best_map', 0.0), ckpt.get('global_step', 0)
        except Exception as e:
            print(f"âš ï¸ ÐÐµ Ð²Ð´Ð°Ð»Ð¾ÑÑ Ð·Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶Ð¸Ñ‚Ð¸ Ñ‡ÐµÐºÐ¿Ð¾Ñ–Ð½Ñ‚: {e}. ÐŸÐ¾Ñ‡Ð¸Ð½Ð°Ñ”Ð¼Ð¾ Ð· Ð½ÑƒÐ»Ñ.")
            return 0, 0.0, 0

    def _save_checkpoint(self, epoch, model, optimizer, scheduler, best_map, global_step, is_best, run_dir):
        state = {
            'epoch': epoch, 'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict(),
            'best_map': best_map, 'global_step': global_step
        }
        last_path = os.path.join(run_dir, "last_checkpoint.pth")
        torch.save(state, last_path)
        if is_best:
            shutil.copyfile(last_path, os.path.join(run_dir, "best_model.pth"))