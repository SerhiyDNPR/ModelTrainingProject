# trainers/SSDTrainer.py

import os
import sys
import datetime as dt
import shutil 
from glob import glob
import torch
import torch.optim as optim
import torch.optim.lr_scheduler as lr_scheduler
from torch.utils.data import DataLoader
import torchvision.transforms as T
import torchvision.models as models
from tqdm import tqdm
from torchvision.ops import Conv2dNormActivation

from DataSetUtils.PascalVOCDataset import PascalVOCDataset
from trainers.trainers import BaseTrainer, collate_fn, log_dataset_statistics_to_tensorboard
from torchmetrics.detection import MeanAveragePrecision
from torch.utils.tensorboard import SummaryWriter

class SSDTrainer(BaseTrainer):
    """
    –ö–µ—Ä—É—î –ø—Ä–æ—Ü–µ—Å–æ–º –Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª–µ–π SSD (SSD300) —Ç–∞ SSDLite (SSD320).
    –ù–∞ –ø–æ—á–∞—Ç–∫—É –∑–∞–ø–∏—Ç—É—î —É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞, —è–∫–∏–π backbone —Ç–∞ —Ä–µ–∂–∏–º –Ω–∞–≤—á–∞–Ω–Ω—è –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏.
    """

    def __init__(self, training_params, dataset_dir):
        super().__init__(training_params, dataset_dir)
        self.model_config = None

    def _ask_training_mode(self):
        """–î–æ–ø–æ–º—ñ–∂–Ω–∏–π –º–µ—Ç–æ–¥, —â–æ –∑–∞–ø–∏—Ç—É—î —Ä–µ–∂–∏–º –Ω–∞–≤—á–∞–Ω–Ω—è."""
        print("\n   –û–±–µ—Ä—ñ—Ç—å —Ä–µ–∂–∏–º –Ω–∞–≤—á–∞–Ω–Ω—è:")
        print("     1: Fine-tuning (–Ω–∞–≤—á–∞—Ç–∏ —Ç—ñ–ª—å–∫–∏ '–≥–æ–ª–æ–≤—É', —à–≤–∏–¥—à–µ, —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ)")
        print("     2: Full training (–Ω–∞–≤—á–∞—Ç–∏ –≤—Å—é –º–æ–¥–µ–ª—å, –¥–æ–≤—à–µ)")
        while True:
            sub_choice = input("   –í–∞—à –≤–∏–±—ñ—Ä —Ä–µ–∂–∏–º—É (1 –∞–±–æ 2): ").strip()
            if sub_choice == '1':
                return '_finetune'
            elif sub_choice == '2':
                return '_full'
            else:
                print("   ‚ùå –ù–µ–≤—ñ—Ä–Ω–∏–π –≤–∏–±—ñ—Ä. –ë—É–¥—å –ª–∞—Å–∫–∞, –≤–≤–µ–¥—ñ—Ç—å 1 –∞–±–æ 2.")

    def _select_backbone_and_mode(self):
        """–í—ñ–¥–æ–±—Ä–∞–∂–∞—î –º–µ–Ω—é –≤–∏–±–æ—Ä—É backbone —Ç–∞ —Ä–µ–∂–∏–º—É, —ñ –ø–æ–≤–µ—Ä—Ç–∞—î –∫–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∏–π —Ä—è–¥–æ–∫."""
        print("\n–ë—É–¥—å –ª–∞—Å–∫–∞, –æ–±–µ—Ä—ñ—Ç—å '—Ö—Ä–µ–±–µ—Ç' (backbone) –¥–ª—è SSD:")
        print("  1: VGG16 (–∫–ª–∞—Å–∏—á–Ω–∏–π, —Ç–æ—á–Ω–∏–π, –∞–ª–µ –ø–æ–≤—ñ–ª—å–Ω–∏–π)")
        print("  2: MobileNetV3-Large (—Å—É—á–∞—Å–Ω–∏–π, –¥—É–∂–µ —à–≤–∏–¥–∫–∏–π, –¥–ª—è real-time)")
        
        while True:
            choice = input("–í–∞—à –≤–∏–±—ñ—Ä (1 –∞–±–æ 2): ").strip()
            backbone_base = None
            if choice == '1':
                print("‚úÖ –í–∏ –æ–±—Ä–∞–ª–∏ VGG16.")
                backbone_base = 'vgg16'
            elif choice == '2':
                print("‚úÖ –í–∏ –æ–±—Ä–∞–ª–∏ MobileNetV3-Large (SSDLite).")
                backbone_base = 'mobilenet'
            else:
                print("‚ùå –ù–µ–≤—ñ—Ä–Ω–∏–π –≤–∏–±—ñ—Ä. –ë—É–¥—å –ª–∞—Å–∫–∞, –≤–≤–µ–¥—ñ—Ç—å 1 –∞–±–æ 2.")
                continue

            training_mode_suffix = self._ask_training_mode()
            self.model_config = f"{backbone_base}{training_mode_suffix}"
            return self.model_config

    def _get_model_name(self):
        """–ü–æ–≤–µ—Ä—Ç–∞—î –ø–æ–≤–Ω—É –Ω–∞–∑–≤—É –º–æ–¥–µ–ª—ñ –¥–ª—è –ª–æ–≥—É–≤–∞–Ω–Ω—è, –±–∞–∑—É—é—á–∏—Å—å –Ω–∞ –≤–∏–±–æ—Ä—ñ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞."""
        if not self.model_config: return "SSD (Unknown)"
        parts = self.model_config.split('_')
        base_name = "SSD (VGG16)" if parts[0] == 'vgg16' else "SSDLite (MobileNetV3)"
        mode_name = "Fine-tune" if parts[1] == 'finetune' else "Full"
        return f"{base_name} {mode_name}"
    
    def _get_model(self, num_classes):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –º–æ–¥–µ–ª—å SSD –∑ –æ–±—Ä–∞–Ω–∏–º backbone —Ç–∞ —Ä–µ–∂–∏–º–æ–º –Ω–∞–≤—á–∞–Ω–Ω—è."""
        print(f"üîß –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ: {self._get_model_name()}")
        
        is_finetune = self.model_config.endswith('_finetune')
        
        if self.model_config.startswith('vgg16'):
            model = models.detection.ssd300_vgg16(weights=models.detection.SSD300_VGG16_Weights.DEFAULT)
        elif self.model_config.startswith('mobilenet'):
            model = models.detection.ssdlite320_mobilenet_v3_large(weights=models.detection.SSDLite320_MobileNet_V3_Large_Weights.DEFAULT)
        else:
            sys.exit(f"‚ùå –ü–æ–º–∏–ª–∫–∞: –Ω–µ–≤—ñ–¥–æ–º–∏–π —Ç–∏–ø –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó '{self.model_config}'.")

        in_channels = []
        for layer in model.head.classification_head.module_list:
            if isinstance(layer, torch.nn.Sequential) and isinstance(layer[0], Conv2dNormActivation):
                in_channels.append(layer[0][0].in_channels)
            else:
                in_channels.append(layer.in_channels)
        
        num_anchors = model.anchor_generator.num_anchors_per_location()
        model.head.classification_head = models.detection.ssd.SSDClassificationHead(
            in_channels, num_anchors, num_classes)
            
        if is_finetune:
            print("‚ùÑÔ∏è –ó–∞–º–æ—Ä–æ–∂—É–≤–∞–Ω–Ω—è –≤–∞–≥ backbone (fine-tuning).")
            for param in model.backbone.parameters():
                param.requires_grad = False
        else:
            print("üî• –£—Å—ñ –≤–∞–≥–∏ –º–æ–¥–µ–ª—ñ —Ä–æ–∑–º–æ—Ä–æ–∂–µ–Ω–æ –¥–ª—è –ø–æ–≤–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è (full training).")

        return model

    def start_or_resume_training(self, dataset_stats):
        if self.model_config is None:
            self._select_backbone_and_mode()

        print(f"\n--- –ó–∞–ø—É—Å–∫ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –¥–ª—è {self._get_model_name()} ---")
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        if self.model_config.startswith('vgg16'):
            imgsz = (512, 512)
            project_dir = os.path.join('runs', f'ssd-vgg16{self.model_config.split("vgg16")[-1]}')
        else: # mobilenet
            imgsz = (512, 512)
            project_dir = os.path.join('runs', f'ssdlite-mobilenet{self.model_config.split("mobilenet")[-1]}')
            
        print(f"üîå –û–±—Ä–∞–Ω–æ –ø—Ä–∏—Å—Ç—Ä—ñ–π: {str(device).upper()}. –†–æ–∑–º—ñ—Ä –∑–æ–±—Ä–∞–∂–µ–Ω—å: {imgsz[0]}x{imgsz[1]}.")

        epochs, batch_size, lr = self.params['epochs'], self.params['batch'], self.params['lr']
        self.accumulation_steps = self.params.get('accumulation_steps', 1)

        train_loader, val_loader, num_classes = self._prepare_dataloaders(batch_size)
        model = self._get_model(num_classes).to(device)
        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)
        lr_step_size = self.params.get('lr_scheduler_step_size', 8)
        lr_gamma = self.params.get('lr_scheduler_gamma', 0.1)
        scheduler = lr_scheduler.StepLR(optimizer, step_size=lr_step_size, gamma=lr_gamma)
        
        run_name, ckpt_path = self._check_for_resume(project_dir)
        start_epoch, best_map, global_step = self._load_checkpoint(ckpt_path, model, optimizer, scheduler, device)
        
        run_dir = os.path.join(project_dir, run_name)
        os.makedirs(run_dir, exist_ok=True)
        writer = SummaryWriter(log_dir=os.path.join(run_dir, 'tensorboard_logs'))
        
        # <-- –ë–õ–û–ö TRY...FINALLY –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–æ–≤–∞–Ω–æ–≥–æ –∑–∞–ø–∏—Å—É –ª–æ–≥—ñ–≤
        try:
            log_dataset_statistics_to_tensorboard(train_loader.dataset, writer)
            print(f"\nüöÄ –†–æ–∑–ø–æ—á–∏–Ω–∞—î–º–æ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –Ω–∞ {epochs} –µ–ø–æ—Ö...")
            
            for epoch in range(start_epoch, epochs):
                global_step = self._train_one_epoch(model, optimizer, train_loader, device, epoch, writer, global_step, imgsz)
                val_map = self._validate_one_epoch(model, val_loader, device, imgsz)
                scheduler.step()
                
                print(f"Epoch {epoch + 1}/{epochs} | Validation mAP: {val_map:.4f}")
                writer.add_scalar('Validation/mAP', val_map, epoch)
                writer.add_scalar('LearningRate/Main', optimizer.param_groups[0]['lr'], epoch)

                writer.flush()

                is_best = val_map > best_map
                if is_best: best_map = val_map
                self._save_checkpoint(epoch + 1, model, optimizer, scheduler, best_map, global_step, is_best, run_dir)

        finally:
            # <-- –î–û–î–ê–ù–û: –ì–∞—Ä–∞–Ω—Ç–æ–≤–∞–Ω–µ –∑–∞–∫—Ä–∏—Ç—Ç—è writer, –Ω–∞–≤—ñ—Ç—å –ø—Ä–∏ –ø–µ—Ä–µ—Ä–∏–≤–∞–Ω–Ω—ñ
            writer.close()
            print("\nüéâ –ù–∞–≤—á–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∞–±–æ –ø–µ—Ä–µ—Ä–≤–∞–Ω–æ. Writer –∑–∞–∫—Ä–∏—Ç–æ.")


    def _prepare_dataloaders(self, batch_size):
        label_map_path = os.path.join(self.dataset_dir, 'label_map.txt')
        with open(label_map_path, 'r') as f: class_names = [line.strip() for line in f.readlines()]
        label_map = {name: i+1 for i, name in enumerate(class_names)}
        num_classes = len(label_map) + 1 
        train_dataset = PascalVOCDataset(os.path.join(self.dataset_dir, 'train'), transforms=None, label_map=label_map)
        val_dataset = PascalVOCDataset(os.path.join(self.dataset_dir, 'val'), transforms=None, label_map=label_map)
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)
        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)
        return train_loader, val_loader, num_classes

    def _train_one_epoch(self, model, optimizer, data_loader, device, epoch, writer, global_step, imgsz):
        model.train()
        progress_bar = tqdm(data_loader, desc=f"Epoch {epoch + 1} [Train]")
        transforms = T.Compose([T.Resize(imgsz), T.ToTensor()])
        optimizer.zero_grad()
        for i, (images, targets) in enumerate(progress_bar):
            images = [transforms(img).to(device) for img in images]
            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]
            loss_dict = model(images, targets)
            losses = sum(loss for loss in loss_dict.values())
            losses = losses / self.accumulation_steps
            losses.backward()
            if (i + 1) % self.accumulation_steps == 0 or (i + 1) == len(data_loader):
                optimizer.step()
                optimizer.zero_grad()
                writer.add_scalar('Train/Loss_step', losses.item() * self.accumulation_steps, global_step)
                global_step += 1
            progress_bar.set_postfix(loss=losses.item() * self.accumulation_steps)
        return global_step

    def _validate_one_epoch(self, model, data_loader, device, imgsz):
        model.eval()
        metric = MeanAveragePrecision(box_format='xyxy').to(device)
        transforms = T.Compose([T.Resize(imgsz), T.ToTensor()])
        with torch.no_grad():
            for images, targets in tqdm(data_loader, desc="Validating"):
                images = [transforms(img).to(device) for img in images]
                predictions = model(images)
                metric.update(predictions, [{k: v.to(device) for k, v in t.items()} for t in targets])
        return metric.compute()['map'].item()

    def _check_for_resume(self, project_path):
        train_dirs = sorted(glob(os.path.join(project_path, "train*")))
        if not train_dirs: return f'train_{dt.datetime.now().strftime("%Y%m%d_%H%M%S")}', None
        last_dir = train_dirs[-1]
        last_ckpt = os.path.join(last_dir, "last_checkpoint.pth")
        if os.path.exists(last_ckpt):
            print(f"\n‚úÖ –í–∏—è–≤–ª–µ–Ω–æ –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è: {last_dir}")
            if input("–ë–∞–∂–∞—î—Ç–µ –ø—Ä–æ–¥–æ–≤–∂–∏—Ç–∏? (y/n): ").strip().lower() in ['y', 'yes', '—Ç–∞–∫', '–Ω']:
                return os.path.basename(last_dir), last_ckpt
        return f'train_{dt.datetime.now().strftime("%Y%m%d_%H%M%S")}', None
    
    def _load_checkpoint(self, path, model, optimizer, scheduler, device):
        if not path: return 0, 0.0, 0
        try:
            ckpt = torch.load(path, map_location=device)
            model.load_state_dict(ckpt['model_state_dict'])
            optimizer.load_state_dict(ckpt['optimizer_state_dict'])
            scheduler.load_state_dict(ckpt['scheduler_state_dict'])
            print(f"üöÄ –í—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è –Ω–∞–≤—á–∞–Ω–Ω—è –∑ {ckpt['epoch']}-—ó –µ–ø–æ—Ö–∏.")
            return ckpt['epoch'], ckpt.get('best_map', 0.0), ckpt.get('global_step', 0)
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —á–µ–∫–ø–æ—ñ–Ω—Ç: {e}. –ü–æ—á–∏–Ω–∞—î–º–æ –∑ –Ω—É–ª—è.")
            return 0, 0.0, 0

    def _save_checkpoint(self, epoch, model, optimizer, scheduler, best_map, global_step, is_best, run_dir):
        state = {
            'epoch': epoch, 'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict(),
            'best_map': best_map, 'global_step': global_step
        }
        last_path = os.path.join(run_dir, "last_checkpoint.pth")
        torch.save(state, last_path)
        if is_best:
            shutil.copyfile(last_path, os.path.join(run_dir, "best_model.pth"))